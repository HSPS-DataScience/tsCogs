---
title: "Model Training Documentation"
author: "Joseph & Trenton"
date: "February 21, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Project Description

The generic framework generated to train a machine learning model producing predictions for subsequent reporting is presented here. The operational prediction code begins, ends, and will run in SQL on HSPSDATA, an SQL Server. However, most of the internals were build in R and nearly all of the model training environment is developed in R. 

The code and method were initially generated, and will be shared here, using eClaim submissions as the example dataset and problem set. Truth was generated using k-means clustering results of the normalized (shape) weekly eClaim profiles. The daily eClaim profiles were trimmed using our own cut-point algorithm and then fed to a feature/cognostic set generator, again developed by our team. Those features become the predictors in the machine learning algorithm. The predictions from the model will help identify which customer accounts are at risk of stopping their use of the product (in this case eClaims). Generating a standardized framework and generic individual components allows for a nearly plug-and-play analysis experience and unparalleled efficiencies.

![Fig. 1 - Model Training Environment/Steps](VOC-modelTrainingDiagram-20180126.PNG)


## Model Training Environment/Steps

### Raw Transactional Data

Jeremie created and runs a script against the production archive to generate a table called *dbo.Claim* on both the DTXHIPAA and EZDHIPAA databases on HSPSDATA. The following view, temporary called *dbo.vwTrentonV2*, in the SupportReports database on HSPSDATA joins a few fields from the *dbo.Claim* table to ultimately tie each ClaimID to an AccountNumber (from Siebel). 

Chad Crawford helped identify an improvement in query speed by moving the DISTINCT selection (necessary because *Siebel.dbo.Assets* duplicates data) inside and apply it to only the data joined from *dbo.Practice*, *dbo.Assets*, *dbo.Accounts*, thus avoiding applying it to the larger *dbo.Claim* or joined *dbo.File_Record* tables.


```{sql sqleClaimJoins, echo = T, eval = F}
USE [SupportReports]
GO

/****** Object:  View [dbo].[vwTrentonV2]    Script Date: 1/30/2018 12:34:38 PM ******/
SET ANSI_NULLS ON
GO

SET QUOTED_IDENTIFIER ON
GO


ALTER VIEW [dbo].[vwTrentonV2]

AS

SELECT Claim_Id      
       , Claim.Create_Date
       , Payer_Id 
       --,Payer_Destination_Id
       , Claim_State
       , Trim.AccountRowId
       , Trim.AccountNum AS AccountNumber
--Select top 100 *
FROM DTXHIPAA.dbo.Claim AS Claim
LEFT JOIN DTXHIPAA.dbo.File_Record AS Fil
       ON Claim.File_Record_ID = Fil.File_Record_ID
LEFT JOIN 
(
       SELECT DISTINCT AccountNum 
              , Acct.AccountRowId
              , Asst.eSrvAdminUser
              , Practice_ID
       FROM DTXHIPAA.dbo.Practice AS Pract
       LEFT JOIN Siebel.dbo.Assets AS Asst
              ON Pract.User_ID_Nbr = eSrvAdminUser
       LEFT JOIN Siebel.dbo.Accounts AS Acct
       ON Asst.AccountRowId = Acct.AccountRowId
              AND Acct.Active = 1
       WHERE Asst.Active = 1
) AS Trim
       ON  Fil.Practice_ID = Trim.Practice_ID


UNION ALL

SELECT Claim_Id      
       ,Claim.Create_Date
       ,Payer_Id 
       --,Payer_Destination_Id
       ,Claim_State
       ,Trim.AccountRowId
       ,Trim.AccountNum AS AccountNumber
FROM EZDHIPAA.dbo.Claim AS Claim
LEFT JOIN EZDHIPAA.dbo.File_Record AS Fil
       ON Claim.File_Record_ID = Fil.File_Record_ID
LEFT JOIN 
(
       SELECT DISTINCT AccountNum 
              , Acct.AccountRowId
              , Asst.eSrvAdminUser
              , Practice_ID
       FROM EZDHIPAA.dbo.Practice AS Pract
       LEFT JOIN Siebel.dbo.Assets AS Asst
              ON Pract.User_ID_Nbr = eSrvAdminUser
       LEFT JOIN Siebel.dbo.Accounts AS Acct
       ON Asst.AccountRowId = Acct.AccountRowId
              AND Acct.Active = 1
       WHERE Asst.Active = 1
) AS Trim
       ON  Fil.Practice_ID = Trim.Practice_ID
GO
```


### Generic Data Profiles

In this case we generate daily profiles of the number of claims submitted by each AccountNumber. This process is summarized in four steps.

1. Generate a daily sequence from Jan 1, 2000 to today.    
2. Create a table of Count = 0 for each day from the start of the data to today.    
3. Summarize the counts (of eClaims submitted) to daily dates by ID (AccountNumber).    
4. Join the summarized counts to include zeros on dates where no eClaims were submitted.    

This approach is agnostic to both summary level (here it's days) and ID (here it's AccountNumber). Below are the two SQL files that generate the daily data profiles by AccountNumber.


```{sql sqlCalendarDays, echo = T, eval = F}

/****** Script to generate daily dates from 01/01/2000 -- GETDATE() ******/

CREATE TABLE [SupportReports].[dbo].[calendarDays]([CalendarDate] DATE);
DECLARE @StartDate DATE;
DECLARE @EndDate DATE;
SET @StartDate = '20000101';
SET @EndDate = GETDATE();
WHILE @StartDate <= @EndDate
    BEGIN
        INSERT INTO [SupportReports].[dbo].[calendarDays]([CalendarDate])
               SELECT @StartDate;
        SET @StartDate = DATEADD(dd, 1, @StartDate);
    END;
```


```{sql sqlGenerateDailyProfiles, echo = T, eval = F}
/****** Generate daily profiles by AccountNumber  ******/
/** https://stackoverflow.com/questions/19075098/how-to-fill-missing-dates-by-groups-in-a-table-in-sql **/
/**	https://stackoverflow.com/questions/7824831/generate-dates-between-date-ranges **/


/** Create the zero daily profile to fill in zeros on the byAccountNumber count data (<1 sec) **/
DECLARE @startDate DATE = '20141001', @endDate DATE = '20160101' --GETDATE()

SELECT DATEADD(DAY, nbr - 1, @startDate) AS ymd
	, 0 AS Count
	INTO SupportReports.dbo.dailyZero
FROM (
  SELECT ROW_NUMBER() OVER( ORDER BY c.object_id ) AS Nbr
	FROM [SupportReports].[dbo].[calendarDate] AS c
	) AS nbrs
WHERE nbr - 1 <= DATEDIFF(DAY, @startDate, @endDate)


/** daily (with holes) counts of claims by AccountNumber (2.5 min) **/
SELECT AccountNumber
	, CONVERT(DATE,[Create_Date]) AS ymd
	--, DATEPART(HOUR, Create_Date) AS hour
	, COUNT(*) AS Count
	INTO SupportReports.dbo.eClaimDailyProfiles
FROM [SupportReports].[dbo].[vwTrentonV2]
WHERE Claim_State IN ('ACCEPTED', 'SETTLED', 'SETTLED ')
GROUP BY AccountNumber, CONVERT(DATE,[Create_Date])--, DATEPART(HOUR, Create_Date) 


/** join of daily claims counts filled in by zeros (28 sec) **/
DECLARE @startDate DATE = '20141001', @endDate DATE = GETDATE()

SELECT dailyZeroAccount.AccountNumber 
	, dailyZeroAccount.ymd
	, COALESCE(eClaimDailyProfiles.Count, 0) AS Count
	INTO SupportReports.dbo.eClaimDailyProfilesExpanded
FROM (
	SELECT AccountNumber, ymd--, Count
	FROM (
		SELECT AccountNumber, @startDate AS minYMD, @endDate AS maxYMD
		FROM SupportReports.dbo.eClaimDailyProfiles
		GROUP BY AccountNumber
	) AS tmp
	CROSS JOIN SupportReports.dbo.dailyZero AS dailyZero
		WHERE dailyZero.ymd BETWEEN tmp.minYMD AND tmp.maxYMD
) AS dailyZeroAccount
	LEFT JOIN 
	SupportReports.dbo.eClaimDailyProfiles AS eClaimDailyProfiles
	ON dailyZeroAccount.AccountNumber = eClaimDailyProfiles.AccountNumber AND 
		 dailyZeroAccount.ymd = eClaimDailyProfiles.ymd
	
ORDER BY dailyZeroAccount.AccountNumber, dailyZeroAccount.ymd;

```


### Cluster and Cut-Point Algorithm

#### k-means Clustering

K-means clustering is an unsupervised machine learning method that requires no response variable (truth) for model fitting. This allowed us to generate the truth as a function of the clustering output. A good visual animated example of kmeans clustering is given [here](http://shabal.in/visuals/kmeans/1.html). We examined several different functions/algorithms implementing kmeans clustering, including:

1. cluster::kmeans()    
    - base R function    

2. cluster::clara()    
    - base R function built for bigger data    

3. biganalytics::bigkmeans()    
    - revolutionAnalytics/Microsoft R function for bigger data     

4. sparklyr::ml_kmeans()    
    - distributed/big data version using Apache Spark     

5. dtwclust::tsclust()  
    - time series clustering    
    - preferable but not scaled for our needs

The sparklyr version ran in six minutes (compared to two hours for the base R version), which made that function the best solution of the five options. In theory natural preference would be to use a time-series clustering approach like dtwClust::tsclust(), however, that function doesn't scale well.  

[INSERT cluster results]


#### Cut-Point Algorithm


### Usage Profile Feature Set


### MODEL (Machine Learning Algorithm)


### Predictions


## Model Prediction Environment/Steps

The one-time run of the model training framework produces the prediction model. Some of the same steps developed for the training framework will be used in the prediction framework to operationalize the methods. The figure below shows those steps which are run weekly and contain identical code (except the PREDICT step) and output. Another documentation file will contain the details for running the weekly prediction steps on the SQL Server (R code run as a stored procedure).

![Fig. 2 - Model Validation Environment/Steps](VOC-modelPredictionDiagram-20180126.PNG)

